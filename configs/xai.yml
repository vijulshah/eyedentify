seed: 42

# dataloader_configs:
  # dataloader_path: "data/eyes/left_eyes/test_dataloader.pth"
  # selected_batch_index: 12 # red = 40, == 12
  # sample_index_in_batch: 110 # red = 20, == 110

img_configs:
  image_path: "data/eyes/right_eyes/6/1/frame_80.png"
  img_size: [32, 64]
  target_value: 2.65945966666667

model_configs:
  model_path: "scripts/mlruns/fold1/ResNet18_right_eyes/artifacts/trained_model/best_model.pt"
  registered_model_name: "ResNet18"
  num_classes: 1

xai_configs:
  viz_path: "inference_n_interpretation/logs_xai_vizualizations"
  methods: [
    # "GuidedGradCam",
    # "IntegratedGradients",
    # "Saliency",
    # "InputXGradient", 
    # "GuidedBackprop",
    # "Deconvolution",

    # "LayerGradCam",
    # "LayerGradientXActivation",

    "CAM",
    # "ScoreCAM",
    # "SSCAM",
    # "ISCAM",
    # "GradCAM",
    # "GradCAMpp",
    # "SmoothGradCAMpp",
    # "XGradCAM",
    # "LayerCAM",
  ] 
# any from: ["CAM", "ScoreCAM", "SSCAM", "ISCAM", "GradCAM", "GradCAMpp", "SmoothGradCAMpp", "XGradCAM", "LayerCAM"] # see here: https://frgfm.github.io/torch-cam/methods.html
  # OR
  # methods: ["InputXGradient"] # any from: ["InputXGradient", "Saliency"] # see here: https://captum.ai/api/
  # OR
  # methods: ["attention_visualization"] # valid only for transformer based models else it will be skipped
